{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear algebra from PBSM3D Laplacian smoothing problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from scipy.io import mmread\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import scipy.sparse.csgraph as graph\n",
    "import scipy.sparse.linalg as linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to read the matrix entries from an input file. Matrices are easy to construct in \"coordinate format\" (COO), but generally we want a \"compressed sparse X\" for efficient algorithms on matrices. This function returns a compressed sparse row (CSR) matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vcl_matrix_file(fileName):\n",
    "    df = pd.read_csv(fileName,header=None,skiprows=1,sep='\\t')\n",
    "    df2 = pd.DataFrame(df[0]).applymap(lambda x: x.strip())\n",
    "    N = len(df2[0])\n",
    "    i = np.zeros(N)\n",
    "    j = np.zeros(N)\n",
    "    val = np.ones(N)\n",
    "    for ii in range(N):\n",
    "        i[ii] = np.int64(re.findall('(\\d+), (\\d+)',df2[0][ii])[0][0])\n",
    "        j[ii] = np.int64(re.findall('(\\d+), (\\d+)',df2[0][ii])[0][1])\n",
    "        val[ii] = np.float(df[1][ii])\n",
    "    A = sparse.coo_matrix((val,(i,j)),shape=(int(i[-1]+1),int(i[-1]+1)))\n",
    "    return sparse.csr_matrix(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data download for Google Colab\n",
    "\n",
    "Only execute this repo clone and dir change if running in Google Colab. If running on your own jupyter notebook env, you can skip ahead to \"Low resolution discretization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Math313'...\n",
      "remote: Enumerating objects: 9, done.\u001b[K\n",
      "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
      "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
      "remote: Total 9 (delta 1), reused 9 (delta 1), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (9/9), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/uofs-simlab/Math313.git\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% cd Math313/20200915_direct_solves_laplacian_smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low resolution discretization\n",
    "\n",
    "Note that there are only 4 (at max) entries in any row. It's just the sheer scale of this thing that makes it look more dense than that.\n",
    "\n",
    "The matrix in `lowRes_mat.out` is a finite volume discretization of $\\left(I-\\nabla^2\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "A = read_vcl_matrix_file('lowRes_mat.out')\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to quickly visualize the sparsity structure of matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mat(A, figsize=(9,8), dpi=80, facecolor=None, edgecolor='k', markersize=0.05, title=\"\", fontsize=20, ticklabelsize=24):\n",
    "    fig=plt.figure(figsize=figsize, dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "    plot=fig.add_subplot(111)\n",
    "    plot.spy(A,markersize=markersize)\n",
    "    Nnz = A.nnz\n",
    "    Nrow = A.shape[0]\n",
    "    ratio = Nnz/(Nrow*Nrow)\n",
    "    plt.title(title, fontsize=fontsize)\n",
    "    plt.xlabel(\"Number of non-zeros: \" + str(Nnz) + \" (%.3f %%)\" %(ratio*100),fontsize=fontsize)\n",
    "    plot.tick_params(axis='both', which='major', labelsize=ticklabelsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mat(A,title=\"Original order\",markersize=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reordering the matrix\n",
    "\n",
    "We can reorder this matrix easily using `scipy`. The reverse Cuthill--McKee (RCM) algorithm orders entries to minimize the bandwidth of the input matrix. The output is a permutation of the input indices. The permuted matrix can be obtained by symmetrically permuting the rows and columns of the original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aperm_indices = graph.reverse_cuthill_mckee(A,symmetric_mode=True)\n",
    "Aperm = A[Aperm_indices,:][:,Aperm_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mat(Aperm,markersize=0.01,title=\"RCM order\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the matrix bandwidth to compare the different orderings. First, write a function that can do this for the CSR storage format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bandwidth_CSR(A):\n",
    "    \"\"\"Compute the maximum bandwidth from a CSR sparse matrix A\"\"\"\n",
    "    assert(sparse.isspmatrix_csr(A))\n",
    "    indices = A.indices\n",
    "    indptr = A.indptr\n",
    "    bandwidth = 0\n",
    "    for row in range(A.shape[0]):\n",
    "        maxind = np.max(indices[indptr[row]:indptr[row+1]])\n",
    "        if maxind-row > bandwidth:\n",
    "            bandwidth = maxind-row\n",
    "    return bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bandwidth of original ordering: \" + str(compute_bandwidth_CSR(A)))\n",
    "print(\"Bandwidth of RCM      ordering: \" + str(compute_bandwidth_CSR(Aperm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct factorization sparsity structures\n",
    "\n",
    "Algorithms for sparse forward/backward substitution are $\\mathcal{O}(nnz)$ where $nnz$ is the number of nonzero entries in the lower triangular factor. If a particular matrix produces a lot of fill-in upon factorization, this can be problematic both for the factorization stage (it doesn't know how much fill-in is coming, so generally ends up allocating memory many times) and the forward/backward substitution stage (there are more operations to perform for eliminations).\n",
    "\n",
    "Start with looking at the $L$ factor in the original ordering. We should see that the number of nonzero entries is much higher than the original matrix due to fill-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Acsc = sparse.csc_matrix(A) # LU solver needs compressed sparse column storage\n",
    "LU = linalg.splu(Acsc,permc_spec=\"NATURAL\") # NATURAL permc_spec means no pivoting\n",
    "# LU = linalg.splu(Acsc,permc_spec=\"NATURAL\",diag_pivot_thresh=0) # If an older scipy version, may need to use this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "visualize_mat(LU.L,title=\"Original order L\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the factorization with the RCM ordering. Observe that the time to compute this factorization is significantly lower than with the original ordering. The resulting number of nonzero entries is also substantially lower than the original ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "Apermcsc = sparse.csc_matrix(Aperm) # LU solver needs compressed sparse column storage\n",
    "LUperm = linalg.splu(Apermcsc,options={ \"Fact\" : \"DOFACT\", \"Equil\" : True, \"ColPerm\" : \"NATURAL\", \"Trans\" : \"NOTRANS\", \"IterRefine\": \"NOREFINE\", \n",
    "  \"DiagPivotThresh\" : 0, \"SymmetricMode\" : True,  \"RowPerm\" : \"NOROWPERM\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mat(LUperm.L,markersize=0.01,title=\"RCM order L\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum fill-in ordering\n",
    "\n",
    "We can produce less fill-in of matrix factors by by using algorithms specifically designed to order unkowns in such a way as to minimize the amount of fill-in. Such methods are usually based around nested dissection (ND).\n",
    "\n",
    "In `scipy`, this functionality is built into the `linalg.splu` function, and is in fact its default behaviour. Because of this, we start by looking at the factor before we look at the entire matrix.\n",
    "\n",
    "Notice, in particular, how much faster this factorization is produced than even the RCM ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "LUpermBEST = linalg.splu(Apermcsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mat(LUpermBEST.L,markersize=0.01,title=\"ND order L\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this particular ordering produces a factor with about a third the amount of entries compared to the factor generated by the RCM ordering.\n",
    "\n",
    "The matrix corresponding to this ordering be obtained by applying the resulting permutation symmetrically (in the `.perm_c` field of the output) to the input matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Abest = Aperm[:,LUpermBEST.perm_c][LUpermBEST.perm_c,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mat(Abest,markersize=0.3,title=\"ND order\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting bandwidth of this ordering is higher than with the RCM ordering, however, we will now show that this is not a bad thing for apply sparse direct solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bandwidth of ND       ordering: \" + str(compute_bandwidth_CSR(Abest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct solve times\n",
    "\n",
    "Before starting with the solves, we construct a rhs resulting from a known solution $u^*=[1,1\\ldots,1]^T$, $b=Au^*$. This allows us to evaluate the accuracy of any solve we perform. \n",
    "\n",
    "(NOTE that the RCM rhs needs to be permuted in accordance with the matrix rows that correspond to it. This is because its ordering was found using a method external to the `splu` method. The ND ordered RHS is the same as the RCM order RHS because the RCM matrix was used as input to `splu`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_star = np.ones(A.shape[0])\n",
    "b_orig = A*u_star\n",
    "b_perm = b_orig[Aperm_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "u_orig = LU.solve(b_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCM ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "u_perm = LUperm.solve(b_perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ND ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "u_best = LUpermBEST.solve(b_perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ND ordered system solves more than 10 times faster on this computer. \n",
    "\n",
    "Finally, looking at the errors of solutions, we see that there is no substantial difference among the orderings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error of original order solve: \" + str(np.linalg.norm(u_star-u_orig)))\n",
    "print(\"Error of RCM      order solve: \" + str(np.linalg.norm(u_star-u_perm)))\n",
    "print(\"Error of ND       order solve: \" + str(np.linalg.norm(u_star-u_best)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
